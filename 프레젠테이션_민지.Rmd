---
title: "데이터 공학 프로젝트 발표"
author: "민형규, 박상우, 정민지, 최호경"
date: '2019-12-13 '
output:
  ioslides_presentation:
    template: quarterly-report.html
---

# 2. 데이터 분석

## 2-1 사용 데이터

데이터 분석을 위해 사용한 데이터는 다음과 같다. 

1. 2015/2016/2019 서울시 축제 정보
- 문화체육관광부 제공 및 카카오 API 사용
- 축제명, 축제기간, 축제장소, 축제설명 등의 정보

[ 관련 파일 및 데이터 경로 ]

- (크롤링 및 전처리 파일) data/preprocess/crawling/crawling_final.ipynb
- (2015/2016년 축제 정보) data/preprocess/crawling/api_crawling.xlsx
- (2019년 축제 정보) data/preprocess/crawling/festival_crawling_2019.xlsx

2. 유동인구(일별 유동인구, 거주지)
- 서울시 빅데이터 캠퍼스 제공. 직접 방문하여 데이터 추출.
- skt에서 수집한 2015년 8월 ~ 2016년 7월의 일단위 성별/연령별 유동인구 데이터
- EPSG:5179 좌표계 사용

[ 관련 파일 및 데이터 경로 ]
- (축제 장소 좌표계 수정) data/preprocess/float_pop/transform_coordinate.ipynb
- (서울시 빅데이터 캠퍼스 데이터 추출 쿼리) data/preprocess/float_pop/분석일자 추가 및 유동인구 데이터 추출 쿼리.ipynb, query_the_day.txt
- (유동인구 데이터) data/preprocess/float_pop/float_pop.xlsx

3. 키워드
- 네이버,다음 뉴스 및 블로그 정보 (출처 - 네이버 및 다음)
(형규)

문화체육관광부에서 제공하는 API와 홈페이지에서 제공하는 축제 정보를 토대로 카카오 API를 사용하여 해당 축제장소의 위경도 좌표 및 주변 맛집 정보를 얻었다. 
축제장소의 위경도를 원점으로 하여 반경 500m(상하좌우 500m)를 축제의 주영향권으로 보고 구역 내의 유동인구를 추출하였다. 
이 데이터는 추후 클러스터링 및 클러스터 예측 모델링에 사용하였다.
유동인구 데이터가 2015년 8월 ~ 2016년 7월만 존재하였으므로 해당 기간에 열린 축제만을 대상으로 하였으며, 그 기간이 일주일이 넘어가는 것은 제외하였다. 위의 전처리 결과 총 73개의 축제만을 분석하였다. 
(* 자세한 전처리 과정과 설명은 위의 파일들 참고)


문화체육관광부에서 제공하는 축제 설명만으로는 축제별 키워드 분석을 진행하기에 그 내용이 부족하였고, 추후 축제 키워드를 활용한 모델링을 할 때 축제 간의 구분 및 연결고리를 더욱 다양화 하기 위해 축제의 뉴스 정보를 크롤링하였다. 


## 2-2 데이터베이스 구축

SQLite를 사용하여 데이터베이스를 구축하였다. 위에서 얻은 raw 데이터들을 전처리하고 얻은 필요한 정보만을 테이블로 추가하였다.

크게 분석용 테이블과 배포용 테이블로 나누어 데이터를 저장하였다. 분석용 테이블은 2015/2016년도의 축제정보와 유동인구 데이터로 이루어져있으며 배포용 테이블은 축제정보, 축제 주변 맛집 정보, 축제의 클러스터 예측정보로 이루어져있다. 배포용 테이블은 추가적인 축제정보 수집을 통해 계속해서 업데이트 될 예정이다. (자동화)

DB 구조는 다음과 같다.

![db_schema](./data/database/db_schema_res.PNG)

[ 데이터 베이스 구축 파일 ]
- (DB 파일) data/database/SEOUL_FESTIVAL.db
- (DB 및 table 생성) data/database/DB 만들기 SEOUL_FESTIVAL.ipynb
- (DB 스키마) data/database/db_schema_res.Rmd

## 4. 향후 운영 방안

## 4-1. 자동화

- 매일 새롭게 업데이트 된 축제 정보를 크롤링하여 데이터베이스에 저장한다. 
- 새롭게 추가된 축제 목록을 가지고 뉴스 크롤링을 하여 키워드 정보를 얻은 뒤 클러스터 예측 모델을 통해 클러스터를 예측한 후 이 또한 데이터베이스에 저장한다. 
- 새롭게 업데이트 된 정보가 사용자에게 뜰 수 있도록 서버를 업데이트한다.
- 위의 모든 작업을 `cron`을 활용해 자동화한다. 

[ 자동화 관련 파일 ]
- data/database/cron.tab
- data/database/festival_auto_crawling_using_crontab.py

## 4-2. 아쉬운 점 및 향후 발전 방안

- 현재 유동인구 데이터의 제한(데이터 없음)으로 인해 최근의 유동인구를 활용한 모델링을 하지 못한 점이 아쉽다.
- 사용자의 인적 정보, 축제 이용후기 등 추가적인 데이터 수집을 통해 보다 맞춤화된 축제 추천이 가능해질 것이다. 
- 사용자 인터페이스 구성에 있어서 축제별 유동인구 정보를 공간정보와 결합해 3D 시각화를 할 수 있다.
- 현재 모바일에 최적화된 UI를 데스크탑에서도 최적화가 가능하다.

